{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn-intelex\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrJETJNdw1Gi",
        "outputId": "8b65832f-6baa-47c2-b955-12902f30372a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn-intelex\n",
            "  Downloading scikit_learn_intelex-2025.9.0-py312-none-manylinux_2_28_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting daal==2025.9.0 (from scikit-learn-intelex)\n",
            "  Downloading daal-2025.9.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-intelex) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-intelex) (1.6.1)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.12/dist-packages (from daal==2025.9.0->scikit-learn-intelex) (2022.3.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.12/dist-packages (from tbb==2022.*->daal==2025.9.0->scikit-learn-intelex) (1.4.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.6.0)\n",
            "Downloading scikit_learn_intelex-2025.9.0-py312-none-manylinux_2_28_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading daal-2025.9.0-py2.py3-none-manylinux_2_28_x86_64.whl (111.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.3/111.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: daal, scikit-learn-intelex\n",
            "Successfully installed daal-2025.9.0 scikit-learn-intelex-2025.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51xlkQQxhxYX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xff_ki_cQZcE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeajr_iTgVjW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/archive_2/states.csv')  # Replace with the path to your file\n",
        "\n",
        "\n",
        "data['DATE'] = pd.to_datetime(data['YEAR'].astype(str) + '-01-01', format='%Y-%m-%d')\n",
        "# Convert 'STATE' column to categorical type\n",
        "data['STATE'] = data['STATE'].astype('category')\n",
        "\n",
        "# Group by 'YEAR' and 'STATE', and aggregate data by summing numerical columns\n",
        "aggregated_data = data.groupby(['YEAR', 'STATE']).sum(numeric_only=True).reset_index()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn5PnKYBhEYD"
      },
      "outputs": [],
      "source": [
        "aggregated_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJkvvTndiF_s"
      },
      "outputs": [],
      "source": [
        "train_dates = pd.to_datetime(aggregated_data['YEAR'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er1PTWNUiW7l"
      },
      "outputs": [],
      "source": [
        "print(train_dates.tail(15)) #Check last few dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCtDoe97kYAy"
      },
      "outputs": [],
      "source": [
        "# Ensure the 'YEAR' column is properly treated as an integer or string\n",
        "aggregated_data['YEAR'] = aggregated_data['YEAR'].astype(str)\n",
        "\n",
        "# Create the 'train_dates' column by appending '-01-01' to each year and converting to datetime\n",
        "train_dates = pd.to_datetime(aggregated_data['YEAR'])\n",
        "\n",
        "# Check the last few dates to ensure correct conversion\n",
        "print(train_dates.tail(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgEsAv3rlOyc"
      },
      "outputs": [],
      "source": [
        "cols = list(aggregated_data)[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXu_PlFJlZct"
      },
      "outputs": [],
      "source": [
        "print(cols) #['Open', 'High', 'Low', 'Close', 'Adj Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZROVIaODlsMA"
      },
      "outputs": [],
      "source": [
        "df_for_training = aggregated_data[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX3tEgNTQwjH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/archive_2/states.csv', index_col='YEAR')\n",
        "print(df.head()) #7 columns, including the Date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dKJma-TRbHU"
      },
      "outputs": [],
      "source": [
        "#Separate dates for future plotting\n",
        "train_dates = pd.to_datetime(df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bueQ-sDOSIOx"
      },
      "outputs": [],
      "source": [
        "train_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5SQ_aEOnchq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d06zOm65wEcW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nMcj4s2nXh4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/archive_2/states.csv', index_col='YEAR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7C4M6KR0qJB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "fname = os.path.join(\"/content/drive/MyDrive/american accent/states1.csv\")\n",
        "\n",
        "with open(fname) as f:\n",
        "    data = f.read()\n",
        "\n",
        "lines = data.split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)\n",
        "print(len(lines))\n",
        "print(lines[0:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuVJrqQgzrBQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "file_path = \"/content/drive/MyDrive/archive_2/states.csv\"  # Update this with the correct path to your file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Move the 'year' column to be the index\n",
        "df = df.set_index('YEAR')\n",
        "\n",
        "# Display the DataFrame with the updated index\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QY0GKwQnlYa"
      },
      "outputs": [],
      "source": [
        "# Check the datatypes of each column\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKu7v6wJnrux"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in the dataset\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Lw_SSunzB3"
      },
      "outputs": [],
      "source": [
        "# Fill null values with the median for each state and year\n",
        "df['ENROLL'] = df.groupby('STATE')['ENROLL'].transform(lambda x: x.fillna(x.median()))\n",
        "df['OTHER_EXPENDITURE'] = df.groupby('STATE')['OTHER_EXPENDITURE'].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5bWOtkkLs51"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_aggregated = df.groupby('YEAR')['TOTAL_REVENUE'].sum().reset_index()\n",
        "df_aggregated['YEAR'] = pd.to_datetime(df_aggregated['YEAR'], format='%Y')\n",
        "df_aggregated.set_index('YEAR', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVyneGQYcMgD"
      },
      "outputs": [],
      "source": [
        "df_aggregated.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YClD6gnLQ0T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4_5vj8hqhZv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6iJYwOdGl2T"
      },
      "outputs": [],
      "source": [
        "# importing the necessary packages.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import geopandas as gpd\n",
        "\n",
        "\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "palette = sns.color_palette('Spectral')\n",
        "pastel = sns.color_palette('pastel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HMSS62fHVgq"
      },
      "outputs": [],
      "source": [
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/archive_2/states.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaTAhQ4RINLC"
      },
      "outputs": [],
      "source": [
        "# Check the datatypes of each column\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_Y_XvsYIbHp"
      },
      "outputs": [],
      "source": [
        "# Fill null values with the median for each state and year\n",
        "df['ENROLL'] = df.groupby('STATE')['ENROLL'].transform(lambda x: x.fillna(x.median()))\n",
        "df['OTHER_EXPENDITURE'] = df.groupby('STATE')['OTHER_EXPENDITURE'].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfEJ3OmuITYY"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in the dataset\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZL7NqEDIfVx"
      },
      "outputs": [],
      "source": [
        "# Select the relevant columns from the DataFrame\n",
        "df_p = df[['YEAR', 'TOTAL_REVENUE']]\n",
        "\n",
        "# Filter the DataFrame to only include data from the years 1992 to 2016\n",
        "df_p = df_p[df_p['YEAR'].between(1992, 2016)]\n",
        "\n",
        "# Create a new column with the president's name based on the year\n",
        "df_p['PRESIDENT'] = df_p['YEAR'].apply(lambda x: 'Bill Clinton' if 1993 <= x <= 2001 else ('George W. Bush' if 2001 <= x <= 2009 else 'Barack Obama'))\n",
        "\n",
        "# Group the data by president and sum the total revenue\n",
        "df_grouped = df_p.groupby('PRESIDENT')['TOTAL_REVENUE'].sum()\n",
        "\n",
        "# Convert the resulting Series to a DataFrame\n",
        "df_presidents = df_grouped.to_frame()\n",
        "\n",
        "# Calculate the tenure of each president in years\n",
        "df_presidents['TENURE'] = df_presidents.index.to_series().apply(lambda x: 8 if x == 'Bill Clinton' else (8 if x == 'George W. Bush' else 8))\n",
        "\n",
        "# Set the president's names as the index of the DataFrame\n",
        "df_presidents.index.name = 'PRESIDENT'\n",
        "\n",
        "# Plot the total education funding per president as a bar chart\n",
        "sns.barplot(data=df_presidents, x=df_presidents.index, y='TOTAL_REVENUE')\n",
        "\n",
        "# Add a title and axis labels\n",
        "plt.title('Total Education Funding per President')\n",
        "plt.xlabel('President')\n",
        "plt.ylabel('Total Funding (in billions)')\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(df_presidents)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "plt.savefig(\"fig1.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wza_hyTEI00X"
      },
      "outputs": [],
      "source": [
        "# Group the data by year and calculate the mean total education funding for each year\n",
        "mean_by_year = df.groupby('YEAR')['TOTAL_REVENUE'].mean()\n",
        "\n",
        "# Plot the mean total education funding by year\n",
        "plt.plot(mean_by_year, label='Mean Total Education Funding')\n",
        "\n",
        "# Plot the education funding of each president\n",
        "for president, group in df_p.groupby('PRESIDENT'):\n",
        "    plt.plot(group['YEAR'], group['TOTAL_REVENUE'], label=president)\n",
        "\n",
        "# Add a legend and show the plot\n",
        "plt.legend()\n",
        "plt.xlabel('YEAR')\n",
        "plt.ylabel('TENURE')\n",
        "plt.show()\n",
        "plt.savefig(\"fig2.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPhG7mwLJIa2"
      },
      "outputs": [],
      "source": [
        "# Create a subplot with 3 rows and 2 columns\n",
        "fig, ax = plt.subplots(3, 2, figsize=(15,15))\n",
        "\n",
        "# Plot the distribution of TOTAL_REVENUE\n",
        "sns.distplot(df['TOTAL_REVENUE'], ax=ax[0][0])\n",
        "ax[0][0].set_title(\"Distribution of TOTAL_REVENUE\")\n",
        "\n",
        "# Plot the distribution of FEDERAL_REVENUE\n",
        "sns.distplot(df['FEDERAL_REVENUE'], ax=ax[0][1])\n",
        "ax[0][1].set_title(\"Distribution of FEDERAL_REVENUE\")\n",
        "\n",
        "# Plot the distribution of STATE_REVENUE\n",
        "sns.distplot(df['STATE_REVENUE'], ax=ax[1][0])\n",
        "ax[1][0].set_title(\"Distribution of STATE_REVENUE\")\n",
        "\n",
        "# Plot the distribution of LOCAL_REVENUE\n",
        "sns.distplot(df['LOCAL_REVENUE'], ax=ax[1][1])\n",
        "ax[1][1].set_title(\"Distribution of LOCAL_REVENUE\")\n",
        "\n",
        "# Plot the distribution of TOTAL_EXPENDITURE\n",
        "sns.distplot(df['TOTAL_EXPENDITURE'], ax=ax[2][0])\n",
        "ax[2][0].set_title(\"Distribution of TOTAL_EXPENDITURE\")\n",
        "\n",
        "# Plot the distribution of INSTRUCTION_EXPENDITURE\n",
        "sns.distplot(df['INSTRUCTION_EXPENDITURE'], ax=ax[2][1])\n",
        "ax[2][1].set_title(\"Distribution of INSTRUCTION_EXPENDITURE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DAAxXphJZeg"
      },
      "outputs": [],
      "source": [
        "# Create a pairplot of the columns\n",
        "sns.pairplot(df, vars=['TOTAL_REVENUE', 'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE', 'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE'])\n",
        "plt.savefig(\"fig3.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUfYuhszWUCv"
      },
      "outputs": [],
      "source": [
        "# Calculate total revenue and expenditure for each state\n",
        "state_totals = df.groupby(['YEAR'])[['TOTAL_REVENUE', 'TOTAL_EXPENDITURE']].sum()\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(state_totals)\n",
        "state_totals.plot()\n",
        "plt.savefig(\"fig4.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsOWwXJ-Jp9m"
      },
      "outputs": [],
      "source": [
        "# Create a subplot with 2 rows and 3 columns\n",
        "fig, ax = plt.subplots(2, 3, figsize=(15,10))\n",
        "\n",
        "# Plot the relationship between ENROLL and TOTAL_REVENUE\n",
        "sns.scatterplot(x=\"ENROLL\", y=\"TOTAL_REVENUE\", data=df, ax=ax[0][0])\n",
        "ax[0][0].set_title(\"ENROLL and TOTAL_REVENUE\")\n",
        "\n",
        "# Plot the relationship between ENROLL and FEDERAL_REVENUE\n",
        "sns.scatterplot(x=\"ENROLL\", y=\"FEDERAL_REVENUE\", data=df, ax=ax[0][1])\n",
        "ax[0][1].set_title(\"ENROLL and FEDERAL_REVENUE\")\n",
        "\n",
        "# Plot the relationship between ENROLL and STATE_REVENUE\n",
        "sns.scatterplot(x=\"ENROLL\", y=\"STATE_REVENUE\", data=df, ax=ax[0][2])\n",
        "ax[0][2].set_title(\"ENROLL and STATE_REVENUE\")\n",
        "\n",
        "# Plot the relationship between ENROLL and LOCAL_REVENUE\n",
        "sns.scatterplot(x=\"ENROLL\", y=\"LOCAL_REVENUE\", data=df, ax=ax[1][0])\n",
        "ax[1][0].set_title(\"ENROLL and LOCAL_REVENUE\")\n",
        "\n",
        "# Plot the relationship between ENROLL and TOTAL_EXPENDITURE\n",
        "sns.scatterplot(x=\"ENROLL\", y=\"TOTAL_EXPENDITURE\", data=df, ax=ax[1][1])\n",
        "ax[1][1].set_title(\"ENROLL and TOTAL_EXPENDITURE\")\n",
        "\n",
        "# Plot the relationship between ENROLL and INSTRUCTION_EXPENDITURE\n",
        "sns.scatterplot(x=\"ENROLL\", y=\"INSTRUCTION_EXPENDITURE\", data=df, ax=ax[1][2])\n",
        "ax[1][2].set_title(\"ENROLL and INSTRUCTION_EXPENDITURE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28jRe1YEgKWp"
      },
      "outputs": [],
      "source": [
        "categoricals =['STATE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4tkpg-4foVT"
      },
      "outputs": [],
      "source": [
        "for col in categoricals:\n",
        "    df[col]=df[col].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtuULzf7WZNo"
      },
      "outputs": [],
      "source": [
        "#separate 2 datasets\n",
        "\n",
        "categoricals = pd.get_dummies(categoricals, columns=['state'])#, prefix = ['type'])\n",
        "categoricals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUtR01gWgl8P"
      },
      "outputs": [],
      "source": [
        "numerics     =['ENROLL','TOTAL_REVENUE','FEDERAL_REVENUE','STATE_REVENUE','LOCAL_REVENUE','TOTAL_EXPENDITURE','INSTRUCTION_EXPENDITURE','SUPPORT_SERVICES_EXPENDITURE','OTHER_EXPENDITURE','CAPITAL_OUTLAY_EXPENDITURE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIO2GM0uPSK8"
      },
      "outputs": [],
      "source": [
        "! pip install shap lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtLI2xSdfXYT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbN3W0Z9hdKC"
      },
      "outputs": [],
      "source": [
        "!pip install pandas # Ensure pandas is installed if it isn't already.\n",
        "# Import the necessary modules\n",
        "import pandas as pd\n",
        "from pandas.api.types import is_numeric_dtype # Import is_numeric_dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md3h4qozhDAw"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    if is_numeric_dtype(df[col]):\n",
        "        continue\n",
        "    else:\n",
        "        df[col]=le.fit_transform(df[col])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95ohtztGmADt"
      },
      "outputs": [],
      "source": [
        "# Declare feature vector and target variable\n",
        "x = df[['ENROLL','TOTAL_EXPENDITURE']]\n",
        "y = df['TOTAL_REVENUE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRG-rW_Dnc9w"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVfctzZXnjoG"
      },
      "outputs": [],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zln4_YlgJw-B"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WxFe8TAJx8p"
      },
      "outputs": [],
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,train_size=0.75,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw8Oy8GUJ73o"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF5_M0X7J3ng"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lereg=LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIxLDESZKj7S"
      },
      "source": [
        "# KNN Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAN1z1x7KhUJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "knn=KNeighborsRegressor(n_neighbors=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JdXVR3_Kv0h"
      },
      "source": [
        "# Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APB2ELvAKsYm"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "RFR=RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN-EzcNOK36y"
      },
      "source": [
        "# DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLeh_guJK0JC"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dtree=DecisionTreeRegressor(max_depth=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRznjILLLCWc"
      },
      "source": [
        "# Support Vector Regression (SVR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFxHg73rK8WL"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "svr_lr=SVR(C=1.0, epsilon=0.2, kernel='linear')\n",
        "svr_rbf=SVR(kernel='rbf',C=1.0,epsilon=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0gzlupOLJdf"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8oZ_yk7LGzP"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "lassoReg = linear_model.Lasso(alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a1_epzqLljN"
      },
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUGY8csILiwY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVxwkgwzLqpq"
      },
      "outputs": [],
      "source": [
        "GDboosing=GradientBoostingRegressor(n_estimators=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3nR3ooxLuBt"
      },
      "source": [
        "# Ada Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBNcmmxgLs-w"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6dcm59WLzD3"
      },
      "outputs": [],
      "source": [
        "AdaBoost=AdaBoostRegressor(n_estimators=15,learning_rate=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNZn_eq2L4-f"
      },
      "source": [
        "# Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwqimjnmL2bl"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsysScmuL8zG"
      },
      "outputs": [],
      "source": [
        "ExtraTree=ExtraTreesRegressor(n_estimators=100,\n",
        "                              random_state=3,\n",
        "                              max_samples=0.5,\n",
        "                              max_features=0.75,\n",
        "                              max_depth=15,\n",
        "                            bootstrap=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XBD9xd9MDVu"
      },
      "source": [
        "# xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2NvYQ6eMA9v"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkDoUPz3MKsg"
      },
      "outputs": [],
      "source": [
        "XGB=XGBRegressor(n_estimators=45,max_depth=5,learning_rate=0.5,device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqHxqAz5MHau"
      },
      "source": [
        "# GaussianProcessRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DrOMt2xMGr5"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "kernel = DotProduct() + WhiteKernel()\n",
        "gaussianReg = GaussianProcessRegressor(kernel=kernel,random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1W_-MFJMXad"
      },
      "source": [
        "# Voting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb7OmQPqMUpq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "rf = RandomForestRegressor(n_estimators=350,random_state=3,max_samples=0.5,max_features=0.75,max_depth=15)\n",
        "gbdt = GradientBoostingRegressor(n_estimators=100,max_features=0.5)\n",
        "xgb = XGBRegressor(n_estimators=25,learning_rate=0.3,max_depth=5)\n",
        "et = ExtraTreesRegressor(n_estimators=100,random_state=3,max_samples=0.5,max_features=0.75,max_depth=10,bootstrap=True)\n",
        "voting_reg = VotingRegressor([('rf', rf), ('gbdt', gbdt), ('xgb',xgb), ('et',et)],weights=[5,1,1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9zuFRMoMbvc"
      },
      "outputs": [],
      "source": [
        "# Optional: Install Intel accelerator for faster training on Colab (run this in a separate cell first)\n",
        "# !pip install scikit-learn-intelex\n",
        "# from sklearnex import patch_sklearn\n",
        "# patch_sklearn()\n",
        "\n",
        "def model(xtrain, ytrain, xtest, ytest):\n",
        "    model_name = [\n",
        "        'LinearRegression', 'KNeighborsRegressor', 'RandomForestRegressor',\n",
        "        'DecisionTreeRegressor', 'linear_model', 'GradientBoostingRegressor',\n",
        "        'AdaBoostRegressor', 'ExtraTreesRegressor', 'XGBRegressor', 'VotingRegressor'\n",
        "        # The following are commented out because they are too slow for this dataset size:\n",
        "        # 'SVR_linear', 'SVR_rbf', 'GaussianProcessRegressor'\n",
        "    ]\n",
        "    accuracy = []\n",
        "\n",
        "    # LinearRegression\n",
        "    print(\"Training LinearRegression...\")\n",
        "    lereg.fit(xtrain, ytrain)\n",
        "    accuracy.append(lereg.score(xtest, ytest))\n",
        "\n",
        "    # KNeighborsRegressor\n",
        "    print(\"Training KNeighborsRegressor...\")\n",
        "    knn.fit(xtrain, ytrain)\n",
        "    accuracy.append(knn.score(xtest, ytest))\n",
        "\n",
        "    # RandomForestRegressor\n",
        "    print(\"Training RandomForestRegressor...\")\n",
        "    RFR.fit(xtrain, ytrain)\n",
        "    accuracy.append(RFR.score(xtest, ytest))\n",
        "\n",
        "    # DecisionTreeRegressor\n",
        "    print(\"Training DecisionTreeRegressor...\")\n",
        "    dtree.fit(xtrain, ytrain)\n",
        "    accuracy.append(dtree.score(xtest, ytest))\n",
        "\n",
        "    # --- SLOW MODELS DISABLED (Uncomment only if dataset is small < 2000 rows) ---\n",
        "    # print(\"Training SVR_linear...\")\n",
        "    # svr_lr.fit(xtrain, ytrain)\n",
        "    # accuracy.append(svr_lr.score(xtest, ytest))\n",
        "\n",
        "    # print(\"Training SVR_rbf...\")\n",
        "    # svr_rbf.fit(xtrain, ytrain)\n",
        "    # accuracy.append(svr_rbf.score(xtest, ytest))\n",
        "    # -----------------------------------------------------------------------------\n",
        "\n",
        "    # linear_model (Lasso)\n",
        "    print(\"Training Lasso (linear_model)...\")\n",
        "    lassoReg.fit(xtrain, ytrain)\n",
        "    accuracy.append(lassoReg.score(xtest, ytest))\n",
        "\n",
        "    # --- SLOW MODEL DISABLED ---\n",
        "    # print(\"Training GaussianProcessRegressor...\")\n",
        "    # gaussianReg.fit(xtrain, ytrain)\n",
        "    # accuracy.append(gaussianReg.score(xtest, ytest))\n",
        "    # ---------------------------\n",
        "\n",
        "    # GradientBoostingRegressor\n",
        "    print(\"Training GradientBoostingRegressor...\")\n",
        "    GDboosing.fit(xtrain, ytrain)\n",
        "    accuracy.append(GDboosing.score(xtest, ytest))\n",
        "\n",
        "    # AdaBoostRegressor\n",
        "    print(\"Training AdaBoostRegressor...\")\n",
        "    AdaBoost.fit(xtrain, ytrain)\n",
        "    accuracy.append(AdaBoost.score(xtest, ytest))\n",
        "\n",
        "    # ExtraTreesRegressor\n",
        "    print(\"Training ExtraTreesRegressor...\")\n",
        "    ExtraTree.fit(xtrain, ytrain)\n",
        "    accuracy.append(ExtraTree.score(xtest, ytest))\n",
        "\n",
        "    # XGBRegressor\n",
        "    print(\"Training XGBRegressor...\")\n",
        "    XGB.fit(xtrain, ytrain)\n",
        "    accuracy.append(XGB.score(xtest, ytest))\n",
        "\n",
        "    # VotingRegressor\n",
        "    print(\"Training VotingRegressor...\")\n",
        "    voting_reg.fit(xtrain, ytrain)\n",
        "    accuracy.append(voting_reg.score(xtest, ytest))\n",
        "\n",
        "    print(\"Done!\")\n",
        "    return model_name, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C63BHm6FnSHc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_name,wosamp_acc=model(xtrain,ytrain,xtest,ytest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCE46-bMMpX_"
      },
      "source": [
        "# Dataframe function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqBlFp1KMwCC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dataframe(y):\n",
        "    vis={'Algorithm':['LinearRegression','KNeighborsRegressor','RandomForestRegressor','DecisionTreeRegressor','linear_model_lasso','GradientBoostingRegressor','AdaBoostRegressor','ExtraTreesRegressor','XGBRegressor','VotingRegressor'],\n",
        "     'Accuracy':y\n",
        "\n",
        "    }\n",
        "    accuracy=pd.DataFrame(vis)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfMlW-Z-M0fd"
      },
      "outputs": [],
      "source": [
        "final_df=pd.DataFrame({\n",
        "    'Algorithm':['LinearRegression','KNeighborsRegressor','RandomForestRegressor','DecisionTreeRegressor','linear_model_lasso','GradientBoostingRegressor','AdaBoostRegressor','ExtraTreesRegressor','XGBRegressor','VotingRegressor']\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpNhizP9M4qb"
      },
      "outputs": [],
      "source": [
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKqjPzAAM-Xz"
      },
      "outputs": [],
      "source": [
        "wosamp_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcP_JPGDNDFG"
      },
      "outputs": [],
      "source": [
        "final_df['Accuracy']=wosamp_acc\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN6jlBnzNIUB"
      },
      "outputs": [],
      "source": [
        "acc_df1=dataframe(wosamp_acc)\n",
        "acc_df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOeM1hSjNMcH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "sns.set()\n",
        "plt.title('Accuracy Comparison')\n",
        "sns.barplot(y=\"Algorithm\",x='Accuracy',data=acc_df1,palette='Set2')\n",
        "sns.set(rc={'figure.figsize':(15,5)})\n",
        "plt.savefig(\"fig5.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. GET THE DATA (Run the model function to get the MAPE scores)\n",
        "# Note: Ensure you have already run the cell with the updated 'def model' code I gave you!\n",
        "model_name, mape_results = model(xtrain, ytrain, xtest, ytest)\n",
        "\n",
        "# 2. CREATE THE DATAFRAME with the correct column name\n",
        "acc_df1 = pd.DataFrame({\n",
        "    'Algorithm': model_name,\n",
        "    'Error Rate (MAPE %)': mape_results  # <--- This creates the column the plot is looking for\n",
        "})\n",
        "\n",
        "# 3. SORT IT (So the best/shortest bars are at the top)\n",
        "acc_df1 = acc_df1.sort_values(by='Error Rate (MAPE %)', ascending=True)\n",
        "\n",
        "# 4. PLOT IT\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.set()\n",
        "\n",
        "plt.title('Model Error Rates (Lower is Better)', fontsize=16)\n",
        "sns.barplot(y=\"Algorithm\", x='Error Rate (MAPE %)', data=acc_df1, palette='viridis')\n",
        "plt.xlabel('Mean Absolute Percentage Error (%)', fontsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xC6ZTmNMWvB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check the data first!\n",
        "# If you see a '0.0' in the 'Error Rate' column, that explains the missing bar.\n",
        "print(acc_df1)\n",
        "\n",
        "# 2. Plot with safeguards\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.set()\n",
        "\n",
        "plt.title('Model Error Rates (Lower is Better)', fontsize=16)\n",
        "\n",
        "# Added 'legend=False' to remove any empty box artifacts\n",
        "sns.barplot(\n",
        "    y=\"Algorithm\",\n",
        "    x='Error Rate (MAPE %)',\n",
        "    data=acc_df1,\n",
        "    palette='viridis',\n",
        "    hue=\"Algorithm\", # Assign hue to avoid future warnings\n",
        "    legend=False     # Turn off the separate legend box\n",
        ")\n",
        "\n",
        "plt.xlabel('Mean Absolute Percentage Error (%)', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wx9Efi4AXhv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgTyXZCDMpSV"
      },
      "source": [
        "NB: GradientBoostingRegressor is the best Algorithm for this Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyL99O6jMmLM"
      },
      "outputs": [],
      "source": [
        "! pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXelOdOrkByA"
      },
      "outputs": [],
      "source": [
        "# import shap library\n",
        "import shap                                                       # SHAP values >> contributions of each feature to a model's prediction for a single instance of data\n",
        "\n",
        "# explain the model's predictions using SHAP\n",
        "explainer = shap.TreeExplainer(RFR)\n",
        "shap_values = explainer.shap_values(xtrain)                                      # numpy array containing the SHAP values calculated for the entire training dataset\n",
        "\n",
        "\n",
        "# visualize the first prediction's explanation\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], xtrain.iloc[0,:])\n",
        "# expected_value = represents the base value which is the average model output over the training dataset\n",
        "# shap_values[0,:]=  extracts the SHAP values for the first row of the data\n",
        "# X_train.iloc[0,:]= first row of the DataFrame\n",
        "plt.savefig(\"sine_wave_plot.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# explain the Gradient Boosting model's predictions using SHAP\n",
        "explainer = shap.TreeExplainer(GDboosing)\n",
        "shap_values = explainer.shap_values(xtrain)\n",
        "# visualize the first prediction's explanation\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], xtrain.iloc[0,:])"
      ],
      "metadata": {
        "id": "lv7dfBIv1axX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoyo6_IxkOgA"
      },
      "outputs": [],
      "source": [
        "# using matplotlib to make a white background for clear visualization----\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the first prediction's explanation with a white background\n",
        "plt.figure(figsize=(10, 4))  # Adjust figure size as needed\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], xtrain.iloc[0,:], matplotlib=True, show=False)\n",
        "plt.gca().set_facecolor('white')  # Set background color to white\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn_39L2ClrqK"
      },
      "outputs": [],
      "source": [
        "# using matplotlib to make a white background for clear visualization----\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the first prediction's explanation with a white background\n",
        "plt.figure(figsize=(10, 4))  # Adjust figure size as needed\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], xtrain.iloc[0,:], matplotlib=True, show=False)\n",
        "plt.gca().set_facecolor('white')  # Set background color to white\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcvA48DapBB3"
      },
      "outputs": [],
      "source": [
        "shap_values = shap.TreeExplainer(RFR).shap_values(xtrain)\n",
        "shap.summary_plot(shap_values, xtrain, plot_type=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-TdmGbEo4Ii"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, xtrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdmr6GRXp6Rh"
      },
      "outputs": [],
      "source": [
        "# import shap library\n",
        "import shap                                                       # SHAP values >> contributions of each feature to a model's prediction for a single instance of data\n",
        "\n",
        "# explain the model's predictions using SHAP\n",
        "explainer = shap.TreeExplainer(XGB)\n",
        "shap_values = explainer.shap_values(xtrain)                                      # numpy array containing the SHAP values calculated for the entire training dataset\n",
        "\n",
        "\n",
        "# visualize the first prediction's explanation\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], xtrain.iloc[0,:])\n",
        "# expected_value = represents the base value which is the average model output over the training dataset\n",
        "# shap_values[0,:]=  extracts the SHAP values for the first row of the data\n",
        "# X_train.iloc[0,:]= first row of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# 1. LOAD DATA\n",
        "try:\n",
        "    data = pd.read_csv('/content/drive/MyDrive/archive_2/states.csv')\n",
        "except:\n",
        "    data = pd.read_csv('states.csv')\n",
        "\n",
        "# 2. THE FIX: REMOVE ROWS WITH MISSING DATA\n",
        "# We drop any row where 'ENROLL' is missing so Plotly doesn't crash\n",
        "data_clean = data.dropna(subset=['ENROLL', 'TOTAL_REVENUE', 'TOTAL_EXPENDITURE', 'YEAR', 'STATE'])\n",
        "\n",
        "# 3. SORT DATA (Required for animation)\n",
        "data_clean = data_clean.sort_values(\"YEAR\")\n",
        "\n",
        "# 4. CREATE INTERACTIVE BUBBLE CHART\n",
        "fig = px.scatter(\n",
        "    data_clean,\n",
        "    x=\"TOTAL_REVENUE\",\n",
        "    y=\"TOTAL_EXPENDITURE\",\n",
        "    animation_frame=\"YEAR\",    # Play Button\n",
        "    animation_group=\"STATE\",   # Smooth movement\n",
        "    size=\"ENROLL\",             # Bubble Size\n",
        "    color=\"STATE\",             # Bubble Color\n",
        "    hover_name=\"STATE\",\n",
        "    log_x=True,                # Log scale helps see small vs big states better\n",
        "    log_y=True,\n",
        "    # Fix the axis range so it doesn't jump around\n",
        "    range_x=[data_clean['TOTAL_REVENUE'].min(), data_clean['TOTAL_REVENUE'].max()],\n",
        "    range_y=[data_clean['TOTAL_EXPENDITURE'].min(), data_clean['TOTAL_EXPENDITURE'].max()],\n",
        "    title=\"Interactive: Revenue vs. Expenditure (1992-2016)\"\n",
        ")\n",
        "\n",
        "# Speed up the animation slightly\n",
        "fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 100\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CyiInjwzfIDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Your existing code above) ...\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# --- ADD THIS TO DOWNLOAD ---\n",
        "# 1. Save the interactive chart as an HTML file\n",
        "fig.write_html(\"interactive_finance_motion_chart.html\")\n",
        "\n",
        "# 2. Download it to your computer (Google Colab specific)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"interactive_finance_motion_chart.html\")\n",
        "except ImportError:\n",
        "    print(\"File saved locally as 'interactive_finance_motion_chart.html'\")"
      ],
      "metadata": {
        "id": "vRnIavcJQw0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Select only the financial/numeric columns\n",
        "# We filter out 'YEAR' and 'STATE' to focus on the money metrics\n",
        "cols_to_corr = ['TOTAL_REVENUE', 'TOTAL_EXPENDITURE', 'FEDERAL_REVENUE',\n",
        "                'STATE_REVENUE', 'LOCAL_REVENUE', 'ENROLL']\n",
        "\n",
        "# 2. Calculate Correlation\n",
        "corr_matrix = data[cols_to_corr].corr()\n",
        "\n",
        "# 3. Plot Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Matrix: State Education Finance', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zQl958nUij4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Select the relevant financial columns\n",
        "# These columns track the money flowing in and out of the state systems\n",
        "cols_finance = ['TOTAL_REVENUE', 'TOTAL_EXPENDITURE',\n",
        "                'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE',\n",
        "                'ENROLL']\n",
        "\n",
        "# 2. Calculate Correlation\n",
        "# Use 'data' (or 'df' depending on your variable name)\n",
        "corr_matrix_fin = data[cols_finance].corr()\n",
        "\n",
        "# 3. Plot the Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix_fin, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Matrix: State Education Finance', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oOniHhULl55K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "    # Group by Year to see the National Average Trend\n",
        "    national_trend = data.groupby('YEAR')['TOTAL_REVENUE'].mean().reset_index()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(x='YEAR', y='TOTAL_REVENUE', data=national_trend, marker='o', color='green', linewidth=2.5)\n",
        "\n",
        "    plt.title('Average State Education Revenue (1992-2016)', fontsize=16)\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Average Revenue ($)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SDLYzk9Rgi80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- FIGURE 2: SCATTER PLOT ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "# This uses 'data' which you just loaded in the previous cell\n",
        "sns.scatterplot(x='ENROLL', y='TOTAL_REVENUE', data=data, alpha=0.5)\n",
        "\n",
        "plt.title('Figure : Enrollment vs. Total Revenue', fontsize=16)\n",
        "plt.xlabel('Total Enrollment')\n",
        "plt.ylabel('Total Revenue ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# --- FIGURE 3: LINE CHART ---\n",
        "# Group by Year to get the national average\n",
        "national_trend = data.groupby('YEAR')['TOTAL_REVENUE'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='YEAR', y='TOTAL_REVENUE', data=national_trend, marker='o', color='green', linewidth=2.5)\n",
        "\n",
        "plt.title('Figure : Average State Revenue (1992-2016)', fontsize=16)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average Revenue ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nsk7e3efjUtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8hahJQlHk76u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}